{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels\n",
    "import pyqtgraph\n",
    "import pickle\n",
    "import graphviz\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "# modelling imports\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz, export_text, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score, confusion_matrix, f1_score, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UHRSWORK</th>\n",
       "      <th>OCC</th>\n",
       "      <th>DEGFIELDD</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>WKSWORK2</th>\n",
       "      <th>VALUEH</th>\n",
       "      <th>OWNCOST</th>\n",
       "      <th>DEGFIELD</th>\n",
       "      <th>EDUCD</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BIRTHYR</th>\n",
       "      <th>PWPUMA00</th>\n",
       "      <th>PROPTX99</th>\n",
       "      <th>TRANTIME</th>\n",
       "      <th>MORTAMT1</th>\n",
       "      <th>DENSITY</th>\n",
       "      <th>SLWT</th>\n",
       "      <th>PROPINSR</th>\n",
       "      <th>YRMARR</th>\n",
       "      <th>ARRIVES</th>\n",
       "      <th>METPOP10</th>\n",
       "      <th>IND</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>HIUID</th>\n",
       "      <th>COSTELEC</th>\n",
       "      <th>PWTYPE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ANCESTR1</th>\n",
       "      <th>ROOMS</th>\n",
       "      <th>BPLD</th>\n",
       "      <th>BPL</th>\n",
       "      <th>RELATED</th>\n",
       "      <th>COSTWATR</th>\n",
       "      <th>STATEICP</th>\n",
       "      <th>RELATE</th>\n",
       "      <th>ANCESTR1D</th>\n",
       "      <th>MET2013</th>\n",
       "      <th>STATEFIP</th>\n",
       "      <th>PWCOUNTY</th>\n",
       "      <th>BUILTYR2</th>\n",
       "      <th>COUNTYFIP</th>\n",
       "      <th>MOVEDIN</th>\n",
       "      <th>COSTGAS</th>\n",
       "      <th>DEPARTS</th>\n",
       "      <th>COUNTYICP</th>\n",
       "      <th>TRANWORK</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>CLASSWKRD</th>\n",
       "      <th>WRKLSTWK</th>\n",
       "      <th>PWMET13</th>\n",
       "      <th>REGION</th>\n",
       "      <th>EMPSTATD</th>\n",
       "      <th>WORKEDYR</th>\n",
       "      <th>CBPERNUM</th>\n",
       "      <th>PWMET13ERR</th>\n",
       "      <th>YNGCH</th>\n",
       "      <th>BEDROOMS</th>\n",
       "      <th>&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>40.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.9</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>374536.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>229301.0</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9400.0</td>\n",
       "      <td>33860.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33860.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>40.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.9</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>374536.0</td>\n",
       "      <td>4380.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>229301.0</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9400.0</td>\n",
       "      <td>33860.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13820.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>40.0</td>\n",
       "      <td>9130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.9</td>\n",
       "      <td>37.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>127506.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>229401.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>40.0</td>\n",
       "      <td>5730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.9</td>\n",
       "      <td>43.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>127506.0</td>\n",
       "      <td>8191.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>229401.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.9</td>\n",
       "      <td>48.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127506.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>229404.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214529</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>30256.0</td>\n",
       "      <td>8191.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>141097301.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214530</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3870.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30256.0</td>\n",
       "      <td>9470.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>141097301.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214531</th>\n",
       "      <td>40.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>260000.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>47703.0</td>\n",
       "      <td>8370.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>141097401.0</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214532</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>3699.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>260000.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.2</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>47703.0</td>\n",
       "      <td>7860.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>141097402.0</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214538</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>141097601.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>9997.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1828069 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UHRSWORK     OCC  DEGFIELDD  EDUC  WKSWORK2    VALUEH  OWNCOST  DEGFIELD  EDUCD   AGE  BIRTHYR  PWPUMA00  PROPTX99  TRANTIME  MORTAMT1  DENSITY   SLWT  PROPINSR  YRMARR  ARRIVES  METPOP10     IND    PUMA        HIUID  COSTELEC  PWTYPE  SEX  ANCESTR1  ROOMS    BPLD   BPL  RELATED  COSTWATR  STATEICP  RELATE  ANCESTR1D  MET2013  STATEFIP  PWCOUNTY  BUILTYR2  COUNTYFIP  MOVEDIN  COSTGAS  DEPARTS  COUNTYICP  TRANWORK  EMPSTAT  CLASSWKRD  WRKLSTWK  PWMET13  REGION  EMPSTATD  WORKEDYR  CBPERNUM  PWMET13ERR  YNGCH  BEDROOMS  >50K\n",
       "2292         40.0   440.0        0.0   6.0       2.0  130000.0    361.0       0.0   63.0  70.0   1948.0    2090.0      25.0       0.0       0.0    168.9  192.0       1.0  1965.0      0.0  374536.0   770.0  2100.0     229301.0    2160.0     5.0  1.0     940.0    8.0   100.0   1.0    101.0     720.0      41.0     1.0     9400.0  33860.0       1.0       0.0       6.0        0.0      7.0   9993.0      0.0        0.0      70.0      1.0       14.0       2.0  33860.0    32.0      10.0       3.0       1.0         1.0   99.0       4.0   1.0\n",
       "2293         40.0  4850.0        0.0   6.0       6.0  130000.0    361.0       0.0   63.0  71.0   1947.0    1300.0      25.0      40.0       0.0    168.9  170.0       1.0  1965.0    734.0  374536.0  4380.0  2100.0     229301.0    2160.0     5.0  2.0     940.0    8.0   100.0   1.0    201.0     720.0      41.0     2.0     9400.0  33860.0       1.0      73.0       6.0        0.0      0.0   9993.0    652.0        0.0      10.0      1.0       22.0       2.0  13820.0    32.0      10.0       3.0       2.0         6.0   99.0       4.0   0.0\n",
       "2294         40.0  9130.0        0.0   6.0       6.0   50000.0    621.0       0.0   63.0  60.0   1958.0    1800.0      12.0      20.0       0.0     82.9   37.0     380.0  2006.0    534.0  127506.0   770.0  1800.0     229401.0    6000.0     9.0  1.0      87.0    8.0   100.0   1.0    101.0      50.0      41.0     1.0      870.0      0.0       1.0       0.0       9.0        0.0      4.0   9993.0    512.0        0.0      10.0      1.0       27.0       2.0      0.0    32.0      10.0       3.0       1.0         0.0   10.0       5.0   0.0\n",
       "2295         40.0  5730.0        0.0   8.0       6.0   50000.0    621.0       0.0   81.0  50.0   1968.0    1800.0      12.0      20.0       0.0     82.9   43.0     380.0  2006.0    739.0  127506.0  8191.0  1800.0     229401.0    6000.0     9.0  2.0      22.0    8.0   100.0   1.0    201.0      50.0      41.0     2.0      220.0      0.0       1.0       0.0       9.0        0.0      0.0   9993.0    717.0        0.0      10.0      1.0       22.0       2.0      0.0    32.0      10.0       3.0       2.0         0.0   10.0       5.0   0.0\n",
       "2297          0.0     0.0        0.0   6.0       0.0   50000.0    621.0       0.0   64.0  60.0   1958.0       0.0      12.0       0.0       0.0     82.9   48.0     380.0     0.0      0.0  127506.0     0.0  1800.0     229404.0    6000.0     0.0  2.0     999.0    8.0   100.0   1.0    801.0      50.0      41.0     8.0     9990.0      0.0       1.0       0.0       9.0        0.0      0.0   9993.0      0.0        0.0       0.0      3.0        0.0       3.0      0.0    32.0      30.0       1.0       4.0         0.0   99.0       5.0   0.0\n",
       "...           ...     ...        ...   ...       ...       ...      ...       ...    ...   ...      ...       ...       ...       ...       ...      ...    ...       ...     ...      ...       ...     ...     ...          ...       ...     ...  ...       ...    ...     ...   ...      ...       ...       ...     ...        ...      ...       ...       ...       ...        ...      ...      ...      ...        ...       ...      ...        ...       ...      ...     ...       ...       ...       ...         ...    ...       ...   ...\n",
       "3214529      30.0  3220.0        0.0   8.0       6.0  275000.0   1250.0       0.0   81.0  55.0   1963.0     500.0      28.0      15.0    1000.0     43.1   80.0    1000.0  2010.0    649.0   30256.0  8191.0   500.0  141097301.0    2400.0     7.0  2.0      32.0    7.0   600.0   6.0    101.0     600.0      68.0     1.0      321.0      0.0      56.0       0.0       5.0        0.0      4.0   9993.0    632.0        0.0      10.0      1.0       23.0       2.0      0.0    41.0      10.0       3.0       1.0         0.0   99.0       4.0   0.0\n",
       "3214530       0.0  3870.0        0.0   6.0       0.0  275000.0   1250.0       0.0   63.0  77.0   1941.0       0.0      28.0       0.0    1000.0     43.1   81.0    1000.0  2010.0      0.0   30256.0  9470.0   500.0  141097301.0    2400.0     0.0  1.0      50.0    7.0  2900.0  29.0    201.0     600.0      68.0     2.0      500.0      0.0      56.0       0.0       5.0        0.0      0.0   9993.0      0.0        0.0       0.0      3.0       27.0       1.0      0.0    41.0      30.0       2.0       2.0         0.0   99.0       4.0   0.0\n",
       "3214531      40.0  5000.0        0.0   6.0       6.0  260000.0    355.0       0.0   65.0  41.0   1977.0     400.0      12.0      20.0       0.0    320.2  102.0       1.0  2004.0    709.0   47703.0  8370.0   400.0  141097401.0    2160.0     9.0  1.0     999.0    7.0  5600.0  56.0    101.0     620.0      68.0     1.0     9990.0      0.0      56.0       0.0       3.0        0.0      5.0    960.0    647.0        0.0      10.0      1.0       22.0       3.0      0.0    41.0      10.0       3.0       1.0         0.0    7.0       5.0   0.0\n",
       "3214532      50.0  2310.0     3699.0  10.0       6.0  260000.0    355.0      36.0  101.0  34.0   1984.0     400.0      12.0      11.0       0.0    320.2   93.0       1.0     0.0    759.0   47703.0  7860.0   400.0  141097402.0    2160.0     9.0  2.0     999.0    7.0  5600.0  56.0   1114.0     620.0      68.0    11.0     9990.0      0.0      56.0       0.0       3.0        0.0      0.0    960.0    747.0        0.0      10.0      1.0       27.0       3.0      0.0    41.0      10.0       3.0       2.0         0.0    7.0       5.0   0.0\n",
       "3214538       0.0     0.0        0.0   7.0       0.0   80000.0   1231.0       0.0   71.0  71.0   1947.0       0.0       5.0       0.0     580.0     43.1   76.0     980.0  2002.0      0.0   30256.0     0.0   500.0  141097601.0     600.0     0.0  1.0      22.0   10.0  5600.0  56.0    101.0    9997.0      68.0     1.0      220.0      0.0      56.0       0.0       9.0        0.0      5.0    840.0      0.0        0.0       0.0      3.0        0.0       1.0      0.0    41.0      30.0       1.0       1.0         0.0   99.0       5.0   1.0\n",
       "\n",
       "[1828069 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = pickle.load( open(\"select_cols.p\", \"rb\"))\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = selected_columns.sample(50000)\n",
    "ttw = selected_columns.sample(1000)\n",
    "tttw = selected_columns.sample(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X = all vars\n",
    "- Xs = all vars sampled (50,000) from total (1,828,069)\n",
    "- Z = selected features\n",
    "- Zs = sampled selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Xs, y, ys = selected_columns.drop(columns=['>50K', 'YRMARR', 'PWTYPE', 'BPLD', 'DEGFIELDD', 'EDUCD', 'PWMET13', 'BIRTHYR', 'SLWT', 'BPLD', 'RELATED', 'ANCESTR1D', 'EMPSTATD', 'PWMET13ERR', 'COUNTYICP']), tw.drop(columns=['>50K', 'YRMARR', 'PWTYPE', 'BPLD', 'DEGFIELDD', 'EDUCD', 'PWMET13', 'BIRTHYR', 'SLWT', 'BPLD', 'RELATED', 'ANCESTR1D', 'EMPSTATD', 'PWMET13ERR', 'COUNTYICP']), selected_columns.filter(['>50K']), tw.filter(['>50K'])\n",
    "\n",
    "Z = selected_columns.filter(['EDUC', 'UHRSWORK', 'OCC', 'VALUEH', 'DEGFIELD', 'AGE', 'SEX', 'RACE', 'TRANWORK'])\n",
    "Zs = tw.filter(['EDUC', 'UHRSWORK', 'OCC', 'VALUEH', 'DEGFIELD', 'AGE', 'SEX', 'RACE', 'TRANWORK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EDUC', 'UHRSWORK', 'OCC', 'VALUEH', 'DEGFIELD', 'AGE', 'SEX', 'TRANWORK']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(Z.columns)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xs, ys, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = X_train.copy()\n",
    "train_df['$$$'] = y_train\n",
    "\n",
    "Z_train, Z_test, q_train, q_test = train_test_split(Z, y, test_size=0.2, random_state=42)\n",
    "Zs_train, Zs_test, qs_train, qs_test = train_test_split(Zs, ys, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "X_train_scaled = std.fit_transform(X_train)\n",
    "Xs_train_scaled = std.fit_transform(Xs_train)\n",
    "Z_train_scaled = std.fit_transform(Z_train)\n",
    "Zs_train_scaled = std.fit_transform(Zs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(Xs, ys)\n",
    "knn_confusion = confusion_matrix(ys_test, knn.predict(Xs_test))\n",
    "plt.figure(dpi=100)\n",
    "sns.heatmap(knn_confusion, cmap=plt.cm.Blues, annot=True, square=True)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('kNN confusion matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 1, Solver = liblinear\n",
      "f1 = 0.012303906490310676\n",
      "r2 train= 0.821725\n",
      "r2 test= 0.6786310152237058\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 1, Solver = newton-cg\n",
      "f1 = 0.012300123001230014\n",
      "r2 train= 0.82175\n",
      "r2 test= 0.6786091342235253\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 1, Solver = sag\n",
      "f1 = 0.011692307692307691\n",
      "r2 train= 0.82175\n",
      "r2 test= 0.6786228098486382\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "C = 1, Solver = lbfgs\n",
      "f1 = 0.011695906432748537\n",
      "r2 train= 0.821775\n",
      "r2 test= 0.6786255449736608\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 10, Solver = liblinear\n",
      "f1 = 0.011083743842364532\n",
      "r2 train= 0.82175\n",
      "r2 test= 0.6786419557237962\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 10, Solver = newton-cg\n",
      "f1 = 0.011083743842364532\n",
      "r2 train= 0.821775\n",
      "r2 test= 0.6786310152237058\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 10, Solver = sag\n",
      "f1 = 0.011695906432748537\n",
      "r2 train= 0.821775\n",
      "r2 test= 0.6786255449736608\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "C = 10, Solver = lbfgs\n",
      "f1 = 0.011083743842364532\n",
      "r2 train= 0.821775\n",
      "r2 test= 0.678636485473751\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 100, Solver = liblinear\n",
      "f1 = 0.011083743842364532\n",
      "r2 train= 0.82175\n",
      "r2 test= 0.6786392205987736\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 100, Solver = newton-cg\n",
      "f1 = 0.011083743842364532\n",
      "r2 train= 0.821775\n",
      "r2 test= 0.678636485473751\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 100, Solver = sag\n",
      "f1 = 0.011083743842364532\n",
      "r2 train= 0.821775\n",
      "r2 test= 0.6786282800986833\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "C = 100, Solver = lbfgs\n",
      "f1 = 0.011083743842364532\n",
      "r2 train= 0.821775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 test= 0.6786392205987736\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "C = 1000, Solver = liblinear\n",
      "f1 = 0.011083743842364532\n",
      "r2 train= 0.82175\n",
      "r2 test= 0.678636485473751\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 1000, Solver = newton-cg\n",
      "f1 = 0.011083743842364532\n",
      "r2 train= 0.821775\n",
      "r2 test= 0.678636485473751\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 1000, Solver = sag\n",
      "f1 = 0.012300123001230014\n",
      "r2 train= 0.821775\n",
      "r2 test= 0.6786091342235253\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "C = 1000, Solver = lbfgs\n",
      "f1 = 0.011083743842364532\n",
      "r2 train= 0.82175\n",
      "r2 test= 0.678636485473751\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 10000, Solver = liblinear\n",
      "f1 = 0.011083743842364532\n",
      "r2 train= 0.82175\n",
      "r2 test= 0.678636485473751\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 10000, Solver = newton-cg\n",
      "f1 = 0.011083743842364532\n",
      "r2 train= 0.821775\n",
      "r2 test= 0.678636485473751\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "C = 10000, Solver = sag\n",
      "f1 = 0.01290719114935464\n",
      "r2 train= 0.821775\n",
      "r2 test= 0.6785790478482772\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "C = 10000, Solver = lbfgs\n",
      "f1 = 0.011083743842364532\n",
      "r2 train= 0.821775\n",
      "r2 test= 0.6786392205987736\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "Cs = [1,10,100,1000,10000]\n",
    "solvers = ['liblinear', 'newton-cg', 'sag', 'lbfgs']\n",
    "f1_scores = []\n",
    "\n",
    "for c in Cs:\n",
    "    for solver in solvers:\n",
    "        lr = LogisticRegression(C=c, solver=solver)\n",
    "        lr.fit(Xs_train_scaled, ys_train)\n",
    "        print('----------------------------------')\n",
    "        print(f\"C = {c}, Solver = {solver}\")\n",
    "        print(f'f1 = {f1_score(lr.predict(Xs_test), ys_test)}')\n",
    "        print(f'r2 train= {lr.score(Xs_train_scaled, ys_train)}')\n",
    "        print(f'r2 test= {lr.score(X_test, ys_train)}')\n",
    "        print('----------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Totally Random Forest !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7df957c90a38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 392\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                                         indices=indices)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_samples_split = [2,4,6,10,20]\n",
    "\n",
    "\n",
    "for num in min_samples_split:\n",
    "    rf = RandomForestClassifier(min_samples_split=num)\n",
    "    rf.fit(Xs_train_scaled, ys_train)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
